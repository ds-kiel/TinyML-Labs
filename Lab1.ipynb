{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ds-kiel/TinyML-Labs/tree/WS23-24/Lab1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ds-kiel/TinyML-Labs/tree/WS23-24/Lab1.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://raw.githubusercontent.com/ds-kiel/TinyML-Labs/tree/WS23-24/Lab1.ipynb\" download><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "whYYztLXJMZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "Before starting, you must click on the \"Copy To Drive\" option in the top bar. Go to File --> Save a Copy to Drive. Name it *'Group\\<Your group number\\>_Lab1.ipynb'*. <ins>This is the master notebook so you will not be able to save your changes without copying it !</ins> Once you click on that, make sure you are working on that version of the notebook so that your work is saved.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "sRUm4vKsc5NL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 1: Machine Learning with Tensorflow\n",
        "\n",
        "Before we can execute a machine learning model on a microcontroller, we first need to create the model, and train it. Especially the training part is quite resource intensive and thus (these days) needs to be performed on a more powerful machine before deployment on a resource-constrained device like a microcontroller.\n",
        "\n",
        "For a start and to get everyone ready for the next steps, you will explore in this lab how to train a neural network with Tensorflow/Keras. Moreover, you will use the [Edge Impulse Python SDK](https://docs.edgeimpulse.com/docs/tools/edge-impulse-python-sdk) to estimate the RAM, ROM, and inference time for your models on the [target platform](https://store.arduino.cc/products/arduino-tiny-machine-learning-kit) which we are going to use for the next labs.\n",
        "\n",
        "In part 1 of this lab, you will explore or recap some machine learning characteristics using the [MNIST dataset](https://www.tensorflow.org/datasets/catalog/mnist), whereas in part 2 you build your own neural networks using either the [Fashion MNIST](https://www.tensorflow.org/datasets/catalog/fashion_mnist) dataset or the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset.\n",
        "\n",
        "## Environment\n",
        "\n",
        "The instructions for this lab come as a [Jupyter Notebook](https://jupyter.org/). You can run it locally in your own Python environment, but we recommend you to use [Google Colab](https://colab.research.google.com) to save your computer hardware, have an instantly working python environment, and allow for easy collaboration.\n",
        "\n",
        "Moreover, you need to obtain an API key from an Edge Impulse project. Register at [edgeimpulse.com](https://edgeimpulse.com/), log in and create a new project. Open the project, navigate to **Dashboard** and click on the **Keys** tab to view your API keys. Double-click on the API key to highlight it, right-click, and select **Copy**. Paste the key below in the cell starting with `ei.API_KEY`.\n",
        "\n",
        "![Copy API key from Edge Impulse project](https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/python-sdk-copy-ei-api-key.png)\n",
        "\n",
        "For this lab you will not use the project in the Edge Impulse Studio. We just need the API Key.\n",
        "\n",
        "## What do you need to hand in?\n",
        "\n",
        "This Jupyter Notebook is intended as a document that you use both for working on the lab as well as for answering the questions. For handing in your lab, please **upload this Jupyter notebook** as well as **a PDF version** of it. Make sure that all images you include are visible in the PDF version."
      ],
      "metadata": {
        "id": "c8mKzT3yottU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLkKlN8QoruN"
      },
      "outputs": [],
      "source": [
        "# If you have not done so already, install the following dependencies\n",
        "!python -m pip install tensorflow scikit-learn edgeimpulse numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "4auRqdLmvt3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import edgeimpulse as ei\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "jxNhJyAkvtU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "x7AdTP4uNNXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "def plot_training_history(history, model_name):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle(f'Model {model_name}')\n",
        "    fig.set_figwidth(15)\n",
        "\n",
        "    ax1.plot(range(1, len(history.history['accuracy'])+1), history.history['accuracy'])\n",
        "    ax1.plot(range(1, len(history.history['val_accuracy'])+1), history.history['val_accuracy'])\n",
        "    ax1.set_title('Model accuracy')\n",
        "    ax1.set(xlabel='epoch', ylabel='accuracy')\n",
        "    ax1.legend(['training', 'validation'], loc='best')\n",
        "\n",
        "    ax2.plot(range(1, len(history.history['loss'])+1), history.history['loss'])\n",
        "    ax2.plot(range(1, len(history.history['val_loss'])+1), history.history['val_loss'])\n",
        "    ax2.set_title('Model loss')\n",
        "    ax2.set(xlabel='epoch', ylabel='loss')\n",
        "    ax2.legend(['training', 'validation'], loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xme7g8AyM5yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paste your Edge Impulse API key string in the `ei.API_KEY` value in the following cell:"
      ],
      "metadata": {
        "id": "MPXbeIOYvb6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ei.API_KEY = \"ei_dae2...\" # Change this to your Edge Impulse API key"
      ],
      "metadata": {
        "id": "SKw7cQM8viBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Tensorflow and MNIST\n",
        "\n",
        "In this part, you will use the standard dataset for getting started with machine learning, so to say the \"Hello World\" of machine learning: MNIST. MNIST is a dataset consisting of 70.000 grayscale images of handwritten digits with a resolution of 28x28 pixels.\n",
        "\n",
        "![Example of MNIST images](https://storage.googleapis.com/tfds-data/visualization/fig/mnist-3.0.1.png)\n",
        "\n",
        "Your task is to run the following models, explore the influence of the number of epochs you use for training, breifly explain the models, and set the models into perspective to each other regarding resource consumption on the *Arduino Nano 33 BLE* (the same MCU used as in the [Arduino Tiny Machine Learning Kit](https://store.arduino.cc/products/arduino-tiny-machine-learning-kit))."
      ],
      "metadata": {
        "id": "LYqj0Ap0vvJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the Data"
      ],
      "metadata": {
        "id": "F6kKigtD6vxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model / data parameters\n",
        "labels = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
        "num_classes = len(labels)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "f38LJd-w6jec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Task 1:** Briefly explain the cell above.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Fb-ni9bY9ATp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the models\n",
        "\n",
        "We build three models:\n",
        "\n",
        "- `model_1`: fully connected neural network with a single hidden dense layer\n",
        "- `model_2`: Convolutional Neural Network (CNN)\n",
        "- `model_3`: Combination of a CNN and a dense layer  "
      ],
      "metadata": {
        "id": "qDD_zX-H93nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model_1\n",
        "def build_model_1(summary=False):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile model_1\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    if summary:\n",
        "        model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "iCh1k5oY_S0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model_2\n",
        "def build_model_2(summary=False):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile model_2\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    if summary:\n",
        "        model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GukD0L-n_f-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model_3\n",
        "def build_model_3(summary=False):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation='relu', input_shape=input_shape))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile model_3\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    if summary:\n",
        "        model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZkRvTaaV_-Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = build_model_1(True)\n",
        "keras.utils.plot_model(model_1, show_shapes=True)"
      ],
      "metadata": {
        "id": "NFGuDvpqqvUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = build_model_2(True)\n",
        "keras.utils.plot_model(model_2, show_shapes=True)"
      ],
      "metadata": {
        "id": "Y9jOIAGkq104"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = build_model_3(True)\n",
        "keras.utils.plot_model(model_3, show_shapes=True)"
      ],
      "metadata": {
        "id": "JOqOztA_q1nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Task 2:** Explain the three models.\n",
        "\n",
        "**<ins>Answer</ins>**\n",
        "\n",
        "Model 1: ...\n",
        "\n",
        "Model 2: ...\n",
        "\n",
        "Model 3: ...\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3hUdr7GFAkcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate model 1"
      ],
      "metadata": {
        "id": "8h-XSP6aRxGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please note:** When you want to retrain a model, you need to create a new model. Otherwise, you will continue training your already trained model."
      ],
      "metadata": {
        "id": "jFDLvdGJrWL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train model 1**"
      ],
      "metadata": {
        "id": "LoOFZjzjsVjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_short = build_model_1()\n",
        "history_1_short = model_1_short.fit(x_train, y_train, batch_size=128, epochs=5, validation_split=0.1)\n",
        "plot_training_history(history_1_short, 1)"
      ],
      "metadata": {
        "id": "zr4rnzqMs99R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_long = build_model_1()\n",
        "history_1_long = model_1_long.fit(x_train, y_train, batch_size=128, epochs=100, validation_split=0.1)\n",
        "plot_training_history(history_1_long, 1)"
      ],
      "metadata": {
        "id": "oWzbjSE7iAWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far we trained our first model once for 5 for once for 100 epochs. But which is the better option? Is more episodes always better?\n",
        "\n",
        "---\n",
        "**Task 3:** Explain the parameters, we used in our fitting function (`fit(x_train, y_train, batch_size=128, epochs=100, validation_split=0.1)`).\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Taks 4:** Which behavior do you observe when training for 5 or for 100 episodes? Especially have a look at the plots.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Task 5:** Why does the validation loss start to increase again when we train for many epochs while the training loss continues to decrease?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "n5HFncE4sCFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluate model 1**"
      ],
      "metadata": {
        "id": "5QH6CnM_u7rW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5 epochs:**"
      ],
      "metadata": {
        "id": "1G38bzsFyl7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_model_1_short = model_1_short.evaluate(x_test, y_test) #, verbose=0)\n",
        "print(\"Test loss (5 epochs):\", score_model_1_short[0])\n",
        "print(\"Test accuracy (5 epochs):\", score_model_1_short[1])\n",
        "\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(model_1_short.predict(x_test),axis=1))\n",
        "# print(cm)\n",
        "\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "cm = pd.DataFrame(cm, index = labels,\n",
        "                  columns = labels)\n",
        "\n",
        "plt.figure(figsize = (4,4))\n",
        "ax = sns.heatmap(cm*100,\n",
        "           annot=True,\n",
        "           fmt='.1f',\n",
        "           cmap=\"Blues\",\n",
        "           cbar=False,\n",
        "              )\n",
        "ax.set_ylabel(\"True Class\", fontdict= {'fontweight':'bold'})\n",
        "ax.set_xlabel(\"Predicted Class\", fontdict= {'fontweight':'bold'})\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FLwEnICbvD7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**100 epochs:**"
      ],
      "metadata": {
        "id": "BxMiQqPtyqE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_model_1_long = model_1_long.evaluate(x_test, y_test) #, verbose=0)\n",
        "print(\"Test loss (100 epochs):\", score_model_1_long[0])\n",
        "print(\"Test accuracy (100 epochs):\", score_model_1_long[1])\n",
        "\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(model_1_long.predict(x_test),axis=1))\n",
        "# print(cm)\n",
        "\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "cm = pd.DataFrame(cm, index = labels,\n",
        "                  columns = labels)\n",
        "\n",
        "plt.figure(figsize = (4,4))\n",
        "ax = sns.heatmap(cm*100,\n",
        "           annot=True,\n",
        "           fmt='.1f',\n",
        "           cmap=\"Blues\",\n",
        "           cbar=False,\n",
        "              )\n",
        "ax.set_ylabel(\"True Class\", fontdict= {'fontweight':'bold'})\n",
        "ax.set_xlabel(\"Predicted Class\", fontdict= {'fontweight':'bold'})\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AzAoQdigyfPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Task 6:** After evaluating the two trained models, which one is better?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Task 7:** Now retrain and evaluate the model and try to find the optimal number of epochs. How many epochs are necessary? How do you know that this is the correct number? *(You can use the cell right below to build your model.)*\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GskacWM7zOes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train optimal model 1\n",
        "num_epochs = ...\n",
        "model_1_optimal = build_model_1()\n",
        "history_1_optimal = model_1_optimal.fit(x_train, y_train, batch_size=128, epochs=num_epochs, validation_split=0.1)\n",
        "plot_training_history(history_1_optimal, 1)"
      ],
      "metadata": {
        "id": "DpehZ_Ag5OZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate optimal model 1\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "y9yHTPiR5ZSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, you manually explored how many epochs are necessary to successfully train the model. However, Tensorflow gives you an option to automate this called [early stopping](https://keras.io/api/callbacks/early_stopping/). See also [here](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/) and [here](https://towardsdatascience.com/a-practical-introduction-to-early-stopping-in-machine-learning-550ac88bc8fd).\n",
        "\n",
        "---\n",
        "**Task 7:** Use an early stopping callback in your fitting function to find the optimal number of epochs. Use reasonable configurations. How many epochs does it train for?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "nFRksQmIzOX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model 1 with early stopping\n",
        "\n",
        "early_stopping_cb = EarlyStopping(\n",
        "    monitor=...,\n",
        "    patience=...,\n",
        "    min_delta=...,\n",
        "    mode=...\n",
        ")\n",
        "\n",
        "num_epochs = 200\n",
        "model_1_es = build_model_1()\n",
        "history_1_es = model_1_es.fit(x_train, y_train, batch_size=128, epochs=num_epochs, validation_split=0.1, callbacks=[early_stopping_cb])\n",
        "plot_training_history(history_1_es, 1)"
      ],
      "metadata": {
        "id": "qTsWQtdm9t5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Task 8:** Explain the parameters you used for your early stopping callback. Why did you choose these?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Task 9:** Now train and evaluate models 2 and 3 below. How do they compare to model 1?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Task 10:** Create a bar plot comparing the models' accuracy. Have a look at [Matplotlib](https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_colors.html) or [Seaborn](https://seaborn.pydata.org/examples/grouped_barplot.html) for creating bar plots.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "59fAJlwP_ArG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train models 2 and 3"
      ],
      "metadata": {
        "id": "8fO7c9JhzOPU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QIrNqcPL_sHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate models 2 and 3"
      ],
      "metadata": {
        "id": "SF9QopjLzN-a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PK0qB3CE_uoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bar plot for task 10\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "Gg2g4q5GCZgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Task 11:** Briefly explain your plot of task 10.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "i2opg5urFhVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On-device resource consumption"
      ],
      "metadata": {
        "id": "56vvpmBDzNsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training your three models we want to know whether we can run them on a microcontroller or whether they are too large. We will use the [Edge Impulse Python SDK](https://docs.edgeimpulse.com/docs/tools/edge-impulse-python-sdk) for profiling, so if you didn't add your API key on top, now is the time.\n",
        "\n",
        "To start, we need to find the right target device for profiling. You are looking for the *Arduino Nano 33 BLE*."
      ],
      "metadata": {
        "id": "EC9jyTSGzNhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List the available profile target devices\n",
        "ei.model.list_profile_devices()"
      ],
      "metadata": {
        "id": "sVRJqHWfD46I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next you can estimate the memory usage and inference time for each of your models."
      ],
      "metadata": {
        "id": "KBFiv3n5ESXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate the RAM, ROM, and inference time for our model on the target hardware family\n",
        "\n",
        "your_model = ...\n",
        "your_device = ...\n",
        "\n",
        "try:\n",
        "    profile = ei.model.profile(model=your_model,\n",
        "                               device=your_device)\n",
        "    print(profile.summary())\n",
        "except Exception as e:\n",
        "    print(f\"Could not profile: {e}\")"
      ],
      "metadata": {
        "id": "m6RlmH7hEEOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Task 12:** Estimate the memory usage and inference time for each of your three final models. **Set your models' performance into perspective to their ROM and RAM usage and their inference time**. Please do **<ins>not</ins>** use a table for this, but plot it, for example with [Matplotlib](https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_colors.html) or [Seaborn](https://seaborn.pydata.org/examples/grouped_barplot.html). Bar plots should be a good option for it. On the x-axis you can list the model and on the y-axis, you can show the respective memory usage for ROM and RAM. *(You can reuse your code for plotting below in part 2.)*\n",
        "\n",
        "**Task 13:** Briefly explain your plot(s) of task 12.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2uywsQdW0AiX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pca2xMDFF1kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Build your own model (FashionMNIST or CIFAR10)\n",
        "\n",
        "In this part you apply your knowledge on classifying image data with neural networks. You can choose whether you want to use the FashionMNIST or the CIFAR10 dataset. Like MNIST both datasets contain images distributed over 10 classes. FashionMNIST should be the easier of the two and CIFAR10 the more challenging dataset.\n",
        "\n",
        "Please choose **one** of the two datasets. If you want to deepen your knowledge on neural networks further, feel free to also try working with the other dataset. **Please mark which of the datasets you choose!**"
      ],
      "metadata": {
        "id": "qWoRUWHGac0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FashionMNIST dataset\n",
        "\n",
        "The FashionMNIST dataset, is a dataset by Zalando similar to the MNIST one you used above. But instead of handwritten digits, the dataset contains 70.000 grayscale images of clothing items with a resolution of 28x28 pixels.\n",
        "\n",
        "Here's an example of how the data looks (each class takes three-rows):\n",
        "\n",
        "![Example of FashionMNIST images](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n",
        "\n",
        "\n",
        "Each clothing items in the dataset is assigned to one of the following labels:\n",
        "\n",
        "\n",
        "| Label | Description |\n",
        "| --- | --- |\n",
        "| 0 | T-shirt/top |\n",
        "| 1 | Trouser |\n",
        "| 2 | Pullover |\n",
        "| 3 | Dress |\n",
        "| 4 | Coat |\n",
        "| 5 | Sandal |\n",
        "| 6 | Shirt |\n",
        "| 7 | Sneaker |\n",
        "| 8 | Bag |\n",
        "| 9 | Ankle boot |\n",
        "\n",
        "You can load and splic the data with\n",
        "\n",
        "```python\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lSeDa7sb7_M6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CIFAR10 dataset\n",
        "\n",
        "The CIFAR10 dataset, is a labeled subset of the [80 million tiny images](http://people.csail.mit.edu/torralba/tinyimages/) dataset by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The CIFAR-10 dataset consists of 60000 colour images with a resolution of 32x32 pixels (input shape: (32, 32, 3)) in 10 classes, with 6000 images per class. The dataset contains 50.000 training images and 10.000 test images.\n",
        "\n",
        "Here's an example of how the data looks:\n",
        "\n",
        "![Example of CIFAR10 images](https://www.tensorflow.org/static/tutorials/images/cnn_files/output_K3PAELE2eSU9_0.png)\n",
        "\n",
        "\n",
        "Each image in the dataset is assigned to one of the following labels:\n",
        "\n",
        "\n",
        "| Label | Description |\n",
        "| --- | --- |\n",
        "| 0 | airplane |\n",
        "| 1 | automobile |\n",
        "| 2 | bird |\n",
        "| 3 | cat |\n",
        "| 4 | deer |\n",
        "| 5 | dog |\n",
        "| 6 | frog |\n",
        "| 7 | horse |\n",
        "| 8 | ship |\n",
        "| 9 | truck |\n",
        "\n",
        "You can load and split the data with\n",
        "\n",
        "```python\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "```"
      ],
      "metadata": {
        "id": "G0GzD7u9dQ3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tasks\n",
        "\n",
        "---\n",
        "\n",
        "**Task 14:**\n",
        "Your task is to design and train neural networks that successfully classify the items in the dataset, and evaluate these models.\n",
        "\n",
        "By successful we mean\n",
        "\n",
        "- for FashionMNIST: each of your models has an accuracy of >85%\n",
        "- for CIFAR10: at least one of your models has an accuracy of >70%\n",
        "\n",
        "Please create at least **three (3)** neural network architectures covering the following categories:\n",
        "\n",
        "- only fully-connected layers\n",
        "- only convolutional layers as hidden layers\n",
        "- a combination of both\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Please keep in mind that your final model should fit onto a microcontroller, namely the *Arduino Nano 33 BLE Sense*. Therefore, use the *Edge Impulse Python SDK* to estimate the models sizes and try to build models that both perform well and fit onto the microcontroller.\n",
        "\n",
        "---\n",
        "\n",
        "**Hand in:**\n",
        "In the notebook you hand in, you should show the models you designed, the training parameters you used, and the performance (accuracy) of your models. Moreover, **set your models' performance into perspective to their ROM and RAM  usage and their inference time**. Please do **<ins>not</ins>** use a table for this, but plot it, for example with [Matplotlib](https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_colors.html) or [Seaborn](https://seaborn.pydata.org/examples/grouped_barplot.html). Bar plots should be a good option for it. On the x-axis you can list the model and on the y-axis, you can show the respective memory usage for ROM and RAM. **Please briefly explain what one can see in your plots.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "mdLYE2LzdYLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the Data"
      ],
      "metadata": {
        "id": "6TEisDCvPzq5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RwzkHydjPzEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the models"
      ],
      "metadata": {
        "id": "21DstlEJP1UX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3og-EUFP3Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the models"
      ],
      "metadata": {
        "id": "t8NurcYMP3_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N7fmOzzVP-hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the models' performance"
      ],
      "metadata": {
        "id": "fBqdQfNeP-zk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Fe4rNSdQCiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Re-nAMF7QGBZ"
      }
    }
  ]
}